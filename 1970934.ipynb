{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# GAMMA Challenge Subtask 2 - Official Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Link for GAMMA:\n",
    "\n",
    "\tMICCAI2021 Contest - GAMMA: https://aistudio.baidu.com/aistudio/competition/detail/90\n",
    "\n",
    "Challenge Description\n",
    "\n",
    "\tThe GAMMA Challenge is an international ophthalmology competition held by Baidu at the MICCAI2021 seminar OMIA8. MICCAI is a comprehensive academic conference in the fields of medical image computing and computer assisted intervention, and is the top conference in these fields. OMIA is an Ophthalmic Medical Image Analysis seminar organized by Baidu at the MICCAI conference, which has been held for eight sessions so far.\n",
    "\n",
    "\tThe GAMMA Challenge focused on glaucoma analysis in multimodal images and consisted of three sub-tasks:  \n",
    "    1) glaucoma grading, 2) macular fovea localization, 3) optic disc and cup segmentation.\n",
    "    \n",
    "Task Description of this baseline\n",
    "\n",
    "    This baseline corresponds to Task 2 of the GAMMA Challenge, which is to predict the macular fovea coordinate values (x, y) in 2D color fundus images.\n",
    "    \n",
    "Dataset Description\n",
    "\n",
    "    The dataset used for this baseline is 2D colour fundus images released in GAMMA. Users can obtain the corresponding datasets by signing up for the GAMMA challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### import the necessary packages\n",
    "\n",
    "import sys \n",
    "sys.path.append('/home/aistudio/external-libraries')\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import euclidean_distances \n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "from paddle.vision.models import resnet50\n",
    "from paddle.io import Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### **Config**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### set the parameters in your framework\n",
    "\n",
    "path = ''  # the path to the training data\n",
    "images_file = path + 'fundus_image/'\n",
    "gt_file = path + 'Fovea_Location_train.xlsx'\n",
    "test_file = ''  # the path to the testing data\n",
    "image_size = 256 # the image size to the network (image_size, image_size, 3)\n",
    "val_ratio = 0.2 # the ratio of train/validation splitition\n",
    "BATCH_SIZE = 32  # batch size\n",
    "iters = 500 # training iteration\n",
    "optimizer_type = 'adam' # the optimizer, can be set as SGD, RMSprop,...\n",
    "num_workers = 4 # Number of workers used to load data\n",
    "init_lr = 1e-4 # the initial learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Train / Val splitition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### divide the training image and the verification image from the training set \n",
    "\n",
    "filelists = os.listdir(images_file)\n",
    "train_filelists, val_filelists = train_test_split(filelists, test_size = val_ratio,random_state = 42)\n",
    "print(\"Total Nums: {}, train: {}, val: {}\".format(len(filelists), len(train_filelists), len(val_filelists)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### load the fundus images from the data folder, \n",
    "### and extract the corresponding ground truth to generate training samples\n",
    "\n",
    "class FundusDataset(Dataset):\n",
    "    def __init__(self, image_file, gt_file=None, filelists=None,  mode='train'):\n",
    "        super(FundusDataset, self).__init__()\n",
    "        self.mode = mode\n",
    "        self.image_path = image_file\n",
    "        image_idxs = os.listdir(self.image_path)\n",
    "        self.gt_file = gt_file\n",
    "\n",
    "        if self.mode == 'train':\n",
    "            label = {row['imgName']: row[1:].values \n",
    "                        for _, row in pd.read_excel(gt_file).iterrows()}\n",
    "            self.file_list = [[image_idxs[i], label[image_idxs[i]]] for i in range(len(image_idxs))]\n",
    "        \n",
    "        elif self.mode == 'test':\n",
    "            self.file_list = [[image_idxs[i], None] for i in range(len(image_idxs))]\n",
    "        \n",
    "        if filelists is not None:\n",
    "            self.file_list = [item for item in self.file_list if item[0] in filelists] \n",
    "   \n",
    "    def __getitem__(self, idx):\n",
    "        real_index, label = self.file_list[idx]\n",
    "        fundus_img_path = os.path.join(self.image_path, real_index)\n",
    "        fundus_img = cv2.imread(fundus_img_path)[:, :, ::-1] # BGR -> RGB        \n",
    "        h,w,c = fundus_img.shape\n",
    "        if self.mode == 'train':\n",
    "            label_nor = (float(label[0])/w, float(label[1])/h)\n",
    "            label_nor = np.array(label_nor).astype('float32').reshape(2)\n",
    "        fundus_re = cv2.resize(fundus_img,(image_size, image_size))\n",
    "        img = fundus_re.transpose(2, 0, 1) # H, W, C -> C, H, W\n",
    "        # print(img.shape)\n",
    "        # img = fundus_re.astype(np.float32)\n",
    "        \n",
    "        if self.mode == 'test':\n",
    "            return img, real_index, h, w\n",
    "        if self.mode == 'train':\n",
    "            return img, label_nor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### generate a _train and a _val Dataset for presenting images in the training dataset\n",
    "\n",
    "_train = FundusDataset(image_file = images_file, \n",
    "                       gt_file=gt_file)\n",
    "_val = FundusDataset(image_file = images_file, \n",
    "                       gt_file=gt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### present five fundus images and corresponding ground truths in the _train Dataset\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(5):\n",
    "    fundus_img, lab = _train.__getitem__(i)\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(fundus_img.transpose(1, 2, 0))\n",
    "    plt.axis(\"off\")\n",
    "    print(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### present five fundus images and corresponding ground truths in the _val Dataset\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(5):\n",
    "    fundus_img, lab = _val.__getitem__(i)\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(fundus_img.transpose(1, 2, 0))\n",
    "    plt.axis(\"off\")\n",
    "    print(lab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This baseline used ResNet50 to extract the feature from fundus images.\n",
    "The detailed introduction of ResNet50 can be found at https://arxiv.org/pdf/1512.03385.pdf .  \n",
    "\n",
    "The code of ResNet50 in PaddlePaddle framework can be found at https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/vision/models/resnet50_cn.html#resnet50 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Network(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.resnet = resnet50(pretrained=True, num_classes=0) # remove final fc 输出为[?, 2048, 1, 1]\n",
    "        self.flatten = paddle.nn.Flatten()\n",
    "        self.linear_1 = paddle.nn.Linear(2048, 512)\n",
    "        self.linear_2 = paddle.nn.Linear(512, 256)\n",
    "        self.linear_3 = paddle.nn.Linear(256, 2)\n",
    "        self.relu = paddle.nn.ReLU()\n",
    "        self.dropout = paddle.nn.Dropout(0.2)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        # print('input', inputs)\n",
    "        y = self.resnet(inputs)\n",
    "        y = self.flatten(y)\n",
    "        y = self.linear_1(y)\n",
    "        y = self.linear_2(y)\n",
    "        y = self.relu(y)\n",
    "        y = self.dropout(y)\n",
    "        y = self.linear_3(y)\n",
    "        y = paddle.nn.functional.sigmoid(y)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cal_ed\n",
    "def cal_ed(logit, label):\n",
    "    ed_loss = []\n",
    "    for i in range(logit.shape[0]):\n",
    "        logit_tmp = logit[i,:].numpy()\n",
    "        label_tmp = label[i,:].numpy()\n",
    "        # print('cal_coordinate_loss_ed', logit_tmp, label_tmp)        \n",
    "        ed_tmp = euclidean_distances([logit_tmp], [label_tmp])\n",
    "        # print('ed_tmp:', ed_tmp[0][0])\n",
    "        ed_loss.append(ed_tmp)\n",
    "    \n",
    "    ed_l = sum(ed_loss)/len(ed_loss)\n",
    "    return ed_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cal_ed_val\n",
    "def cal_ed_val(logit, label):\n",
    "    ed_loss = []\n",
    "    for i in range(logit.shape[0]):\n",
    "        logit_tmp = logit[i,:]\n",
    "        label_tmp = label[i,:]\n",
    "        ed_tmp = euclidean_distances([logit_tmp], [label_tmp])\n",
    "        ed_loss.append(ed_tmp)\n",
    "    \n",
    "    ed_l = sum(ed_loss)/len(ed_loss)\n",
    "    \n",
    "    return ed_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# loss\n",
    "def cal_coordinate_Loss(logit, label, alpha = 0.5):\n",
    "    \"\"\"\n",
    "    logit: shape [batch, ndim]\n",
    "    label: shape [batch, ndim]\n",
    "    ndim = 2 represents coordinate_x and coordinaate_y\n",
    "    alpha: weight for MSELoss and 1-alpha for ED loss\n",
    "    return: combine MSELoss and ED Loss for x and y, shape [batch, 1]\n",
    "    \"\"\"\n",
    "    alpha = alpha\n",
    "    mse_loss = nn.MSELoss(reduction='mean')\n",
    "\n",
    "    mse_x = mse_loss(logit[:,0],label[:,0])\n",
    "    mse_y = mse_loss(logit[:,1],label[:,1])\n",
    "    mse_l = 0.5*(mse_x + mse_y)\n",
    "    # print('mse_l', mse_l)\n",
    "\n",
    "    ed_loss = []\n",
    "    # print(logit.shape[0])\n",
    "    for i in range(logit.shape[0]):\n",
    "        logit_tmp = logit[i,:].numpy()\n",
    "        label_tmp = label[i,:].numpy()\n",
    "        # print('cal_coordinate_loss_ed', logit_tmp, label_tmp)        \n",
    "        ed_tmp = euclidean_distances([logit_tmp], [label_tmp])\n",
    "        # print('ed_tmp:', ed_tmp[0][0])\n",
    "        ed_loss.append(ed_tmp)\n",
    "    \n",
    "    ed_l = sum(ed_loss)/len(ed_loss)\n",
    "    # print('ed_l', ed_l)\n",
    "    # print('alpha', alpha)\n",
    "    loss = alpha * mse_l + (1-alpha) * ed_l\n",
    "    # print('loss in function', loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Training function\n",
    "\n",
    "def train(model, iters, train_dataloader, val_dataloader, optimizer, log_interval, evl_interval):\n",
    "    iter = 0\n",
    "    model.train()\n",
    "    avg_loss_list = []\n",
    "    avg_ED_list = []\n",
    "    best_ED = sys.float_info.max\n",
    "    while iter < iters:\n",
    "        for img, lab in train_dataloader:\n",
    "            iter += 1\n",
    "            if iter > iters:\n",
    "                break\n",
    "            fundus_imgs = (img / 255.).astype('float32')\n",
    "            label = lab.astype(\"float32\")\n",
    "\n",
    "            logits = model(fundus_imgs)\n",
    "            loss = cal_coordinate_Loss(logits, label)\n",
    "            # print('loss in train',loss)\n",
    "\n",
    "            for p,l in zip(logits.numpy(), label.numpy()):\n",
    "                avg_ED_list.append([p,l])\n",
    "            \n",
    "            # print('avg_ED_list', avg_ED_list)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            model.clear_gradients()\n",
    "            avg_loss_list.append(loss.numpy()[0])\n",
    "            \n",
    "            if iter % log_interval == 0:\n",
    "                avg_loss = np.array(avg_loss_list).mean()\n",
    "                # print(avg_loss)\n",
    "                avg_ED_list = np.array(avg_ED_list)\n",
    "                avg_ED = cal_ed_val(avg_ED_list[:, 0], avg_ED_list[:, 1]) # cal_ED\n",
    "                # print('ed in training', avg_ED)\n",
    "                avg_loss_list = []\n",
    "                avg_ED_list = []\n",
    "                \n",
    "                print(\"[TRAIN] iter={}/{} avg_loss={:.4f} avg_ED={:.4f}\".format(iter, iters, avg_loss, avg_ED[0][0]))\n",
    "\n",
    "            if iter % evl_interval == 0:\n",
    "                avg_loss, avg_ED = val(model, val_dataloader)\n",
    "                print(\"[EVAL] iter={}/{} avg_loss={:.4f} ED={:.4f}\".format(iter, iters, avg_loss, avg_ED[0][0]))\n",
    "                if avg_ED <= best_ED:\n",
    "                    best_ED = avg_ED[0][0]\n",
    "                    paddle.save(model.state_dict(),\n",
    "                            os.path.join(\"best_model_{:.4f}\".format(best_ED), 'model.pdparams'))\n",
    "                model.train()\n",
    "\n",
    "### validation function\n",
    "\n",
    "def val(model, val_dataloader):\n",
    "    model.eval()\n",
    "    avg_loss_list = []\n",
    "    cache = []\n",
    "    with paddle.no_grad():\n",
    "        for data in val_dataloader:\n",
    "            fundus_imgs = (data[0] / 255.).astype(\"float32\")\n",
    "            labels = data[1].astype('float32')\n",
    "            \n",
    "            logits = model(fundus_imgs)\n",
    "            for p, l in zip(logits.numpy(), labels.numpy()):\n",
    "                cache.append([p, l])\n",
    "\n",
    "            loss = cal_coordinate_Loss(logits, labels)\n",
    "            avg_loss_list.append(loss.numpy()[0])\n",
    "\n",
    "    cache = np.array(cache)\n",
    "    ED = cal_ed_val(cache[:, 0], cache[:, 1])\n",
    "    avg_loss = np.array(avg_loss_list).mean()\n",
    "\n",
    "    return avg_loss, ED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### generate training Dataset and validation Dataset \n",
    "\n",
    "train_dataset = FundusDataset(image_file = images_file, \n",
    "                       gt_file=gt_file,\n",
    "                       filelists=train_filelists)\n",
    "\n",
    "val_dataset = FundusDataset(image_file = images_file, \n",
    "                       gt_file=gt_file,\n",
    "                       filelists=val_filelists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Load the samples\n",
    "\n",
    "train_loader = paddle.io.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_sampler=paddle.io.DistributedBatchSampler(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=False),\n",
    "    # num_workers=num_workers,\n",
    "    return_list=True,\n",
    "    use_shared_memory=False\n",
    ")\n",
    "\n",
    "val_loader = paddle.io.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_sampler=paddle.io.DistributedBatchSampler(val_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=False),\n",
    "    # num_workers=num_workers,\n",
    "    return_list=True,\n",
    "    use_shared_memory=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Model code was used to generate Model instance, and Optimizer were defined for subsequent training.\n",
    "\n",
    "model = Network()\n",
    "\n",
    "if optimizer_type == \"adam\":\n",
    "    optimizer = paddle.optimizer.Adam(init_lr, parameters=model.parameters())\n",
    "\n",
    "# criterion = cal_coordinate_Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### training process\n",
    "\n",
    "train(model, iters, train_loader, val_loader, optimizer, log_interval=10, evl_interval=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### inference(testing) process, load the model parameters\n",
    "\n",
    "best_model_path = \"./best_model_0.0416/model.pdparams\"\n",
    "model = Network()\n",
    "para_state_dict = paddle.load(best_model_path)\n",
    "model.set_state_dict(para_state_dict)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### gerenate the test Dataset\n",
    "\n",
    "test_dataset = FundusDataset(image_file = test_file, \n",
    "                       mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### The fundus images in the test dataset are localizated one by one\n",
    "\n",
    "cache = []\n",
    "for fundus_img, idx, h, w in test_dataset:\n",
    "    fundus_img = fundus_img[np.newaxis, ...]    \n",
    "    fundus_img = paddle.to_tensor((fundus_img / 255.).astype(\"float32\"))    \n",
    "    logits = model(fundus_img)\n",
    "    pred_coor = logits.numpy()\n",
    "    # print(pred_coor)\n",
    "    x = pred_coor[0][0] * w\n",
    "    y = pred_coor[0][1] * h\n",
    "    cache.append([idx, x, y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### save the predicted results in .csv file\n",
    "\n",
    "submission_result = pd.DataFrame(cache, columns=['data', 'Fovea_X', 'Fovea_Y'])\n",
    "submission_result[['data', 'Fovea_X', 'Fovea_Y']].to_csv(\"./Localization_Results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "    This baseline realized the prediction of macular fovea coordinate value in 2D color fundus photos. The baseline model was ResNet50.\t      \n",
    "\tUsers can try other tricks on the basis of this baseline, such as joint training with optic disc localization or segmentation task, joint training with macular segmentation task, and achieving macular fovea localization from coarse to fine."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.0.0b0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
